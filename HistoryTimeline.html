<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="HistoryTimeline.css">
        <link rel="stylesheet" href="backgroundColor.css">
        <link rel="stylesheet" href="Buttons.css">
        <link rel="stylesheet" href="navBar.css">
        <title>Refrences</title>
        <meta charset="UTF-8">
    </head>
    <body>
        <div class="navbar">
            <ul>
                <li><a href="Index.html">Home</a></li>
                <li><a href="Introduction.html">Introduction</a></li>
                <li><a href="Implications.html">Societal Implications</a></li>
                <li><a href="History&Development.html">History And Development</a></li>
                <li><a href="HistoryTimeline.html">Timeline</a></li>
                <li><a href="Bibliography.html">References</a></li>
            </ul>
        </div>
        <br>
        <div class="title">
            <h1>History Timeline</h1>
        </div>
        <br>
        <table>
            <tr>
              <td class="year">
                <p>
                    <strong>
                      1950 - Alan Turing
                    </strong>
                </p>
              </td>
              <td class="paragraph">
                  <img src="img/Alan_Turing_1950 (1).jpg" style="float: left; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                  <p>
                      Alan Turing (June 23, 1912 - June 7, 1954) is a world renowned scientist and a founding father of modern day 
                      computing. His book titled “Computing Machinery and Intelligence” was a major propelling force leading to the 
                      birth of AI. This book proposed the question; “Can machines think?” and recommended a new test called the 
                      Turing Test, in order to measure the intelligence of a computer in comparison to humans. He proposed that 
                      if provided with the same information as a human then what’s stopping an AI from using problem solving skills 
                      and logic in order to solve real world problems. So by using the Turing test Alan allowed a computer to monitor 
                      a conversation between humans and then had it create human-like responses to the questions posed. This kickstarted 
                      the drive for AI and made scientists around the world invest their time and money into researching AI.
                    </p>
              </td>
            </tr>
            <tr>
              <td class="paragraph">
                <img src="img/AI_1956.jpg" style="float: right; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                  <p>
                      The term “Artificial Intelligence” was first coined by John Mcarthy (September 4, 1927 – October 24, 2011) 
                      who was an American computer scientist and cognitive scientist. When AI was still in its early stages of discovery, 
                      Mcarthy was the person to first introduce this topic at the world's first-ever AI conference at Dartmouth College. 
                      Upon Mcarthys’ lecture on the topic of AI, later that year, Allen Newell, a researcher in computer science and cognitive 
                      psychology, J.C. Shaw, a systems programmer, and Herbert Simmon, a American political scientist, created a software 
                      programmer known as Logic Theorist, which was the first-ever running software program. The Logic Theorist was the first 
                      software program that was capable of performing automated reasoning and was known as the first artificial intelligence 
                      program.
                    </p>
              </td>
              <td class="year">
                  <p>
                      <strong>
                          1956 - Artificial Intelligence
                        </strong>
                    </p>
              </td>
            </tr>
            <tr>
              <td class="year">
                  <p>
                      <strong>
                          1967 - Fran Rosenblatt
                        </strong>
                  </p>
              </td>
              <td class="paragraph">
                <img src="img/Frank Rosenblatt 1967 (2).jpg" style="float: left; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                  <p>
                    Fran Rosenblatt, sometimes referred to as the father of Deep Learning, was the architect of Deep Learning. 
                    Fran was the first person to create a computer based on neural networks, he called it the Mark 1 Perceptron. 
                    It used simple Neural Networks composed of 2 layers, an input and an output layer. Put simply the perceptron took in 
                    an input, multiplied it by a learning weight coefficient and created an output as a function of the input. Then it 
                    adjusts the learning weight coefficient based on the accuracy of the output and then tries again. Through trial and 
                    error the AI improves its accuracy and eventually starts to simulate the human thought process. This was the first 
                    computer that could learn the most basic types of differentiation on its own without the need of human interference. 
                  </p>
              </td>
            </tr>
            <tr>
                <td class="paragraph">
                    <img src="img/Neural_Networks.png" style="float: right; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                    <p>
                      Neural Networks started becoming necessities in the world of AI in the 1980s. A Neural Network is an assortment of 
                      algorithms modeled after the human brain. They can interpret sensory data by using machine perception and they can 
                      label or cluster raw data. They’re main purpose is to be able to recognize numerical patterns which are contained 
                      in vectors. All real world data is translated to these vectors in order to be analyzed by the machine. There are 2 
                      main types of Neural Networks, simple Neural Networks and Deep Neural Networks. Simple Neural Networks are made up 
                      of 2 layers, one input and one output. The input is given as a vector which the AI then applies a learning weight 
                      coefficient to the input in order to generate an output as a function of the input. Essentially, a Neural Network 
                      will take in raw data, classify and categorize it based on similarities found in the data based on a labeled 
                      training data set. The AI can then measure its accuracy and then adjust the learning weight coefficient and 
                      algorithms based on how close it was to being correct. These Neural Networks created a drive to learn more about 
                      AI and it’s creation is what made AI the primary force in computing. Widespread use of simple and deep/complex 
                      Neural Networks began to dominate the field of AI and Deep Learning. Though simple Neural Networks were easier to 
                      create, deep Neural Networks were much more versatile than the simple Neural Networks since they had more than just 
                      an Input and Output layer. Deep Neural Networks have at least 1 processing layer between the input and output, 
                      they take in raw data and send them to the Neurons. The Neurons then compute the weighted average of the input data 
                      and pass them through an activation function which is essentially a nonlinear function. The data is then sent to 
                      other Neurons through the use of connections. Each connection has a weight on it which represents how powerful the 
                      connection between both Neurons is, the higher the weight the more possibility for error. The aim is to reduce the 
                      weight value so that there would be less room for error. The error is given a value through the Propagation function 
                      which provides the “predicted value” and the “error value”. Once each iteration is completed the AI generates a 
                      Learning Rate which decides how quickly or how slowly the weight values should be updated. By repeating this 
                      process the Neural Network can keep reducing the weights on the connections which results in a greater accuracy for 
                      its predictions. 
                    </p>
                </td>
                <td class="year">
                    <p>
                        <strong>
                            1980s - Neural Networks
                        </strong>
                    </p>
                </td>
              </tr>
              <tr>
                <td class="year">
                    <p>
                        <strong>
                            1995 - 1997 - IBM’s Deep Blue
                        </strong>
                    </p>
                </td>
                <td class="paragraph">
                    <img src="img/IBM Deep Blue.jpg" style="float: left; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                    <p>
                        International Business Machines(IBM) created an AI, named Deep Blue, through the use of Deep Machine Learning 
                        and deep Neural Networks. Deep Blue was a chess playing expert run on a IBM Supercomputer, and it was the 
                        first computer to win a chess match against a world champion. Deep Blue was originally named Deep Thought in 
                        1995 and its prototype was developed in the same year when it was renamed to Deep Blue. In 1996, Deep Blue 
                        first faced Garry Kasparov in a six-game match where it lost 2-4. Then IBM upgraded the AI and in 1997, in a 
                        six-game rematch, it won 3-2  and drew one. This was considered a major milestone in the history of AI and 
                        proved to the world that AI can be smarter than humans and that they can learn through failure. 
                    </p>
                </td>
              </tr>
              <tr>
                <td class="paragraph">
                    <img src="img/Jeopard AI.jpg" style="float: right; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                    <p>
                        Watson was a question-answering AI capable of answering questions posed by people. IBM developed Watson and 
                        named it after its founder and CEO, Thomas J. Watson. The computer was developed to answer questions on 
                        Jeopardy, a famous quiz show, by looking for hints in the question and comparing it to hundreds of potential 
                        solutions within its database to see which one makes the most sense. In 2011 it competed against the then world 
                        champions, Brad Rutter and Ken Jennings, and won the $1 million cash prize.
                    </p>
                </td>
                <td class="year">
                    <p>
                        <strong>
                            2011 - Jeopardy AI
                        </strong>
                    </p>
                </td>
              </tr>
              <tr>
                <td class="year">
                    <p>
                        <strong>
                            2015 - Baidu Minwa Convolutional Neural Network
                        </strong>
                    </p>
                </td>
                <td class="paragraph">
                    <img src="img/Baidu Minwa.jpg" style="float: left; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                    <p>
                        Chinese Search Giant Baidu created Minwa, a supercomputer that uses a deep neural networks combination 
                        known as a convolutional neural network to differentiate images at a higher frequency than the average 
                        humans. This supercomputer was able to identify 95.42% of images out of a million, averaging better than 
                        Microsoft, Google and even most humans. Minwa was put into a database called ImageNet which had over 
                        1 million images where it then needed to learn how to sort the pictures into around 1000 predefined categories. 
                        The computer had to learn to find small differences between very similar images, some images were even cropped 
                        and distorted so the AI learned to find the key details and differentiate the image. Minwa even had to recognize 
                        pictures that were slanted, printed or even a picture of the picture. The super computer was so powerful, 
                        that it would have easily been in the top 300 most powerful computers globally if it wasn’t designed solely 
                        for Deep Learning purposes. This computer had a whopping 144 GPUs and 72 processors, much more than a normal 
                        computer. The Neural Network the supercomputer uses has billions of connections, hundreds of times more than 
                        any of its predecessors. The endeavor served as a great reminder as to how powerful AI and Deep Learning 
                        actually is. 
                    </p>
                </td>
              </tr>
              <tr>
                <td class="paragraph">
                    <img src="img/Alpha Go AI.png" style="float: right; width: 250px; height: 250px; margin: 10px; border: solid; border-color: skyblue; border-width: 6px;">
                    <p> 
                        DeepMind is a British Artificial Intelligence company and a subsidiary of Alphabet Inc, the parent company of 
                        Google. It created a supercomputer and AI called AlphaGo which was designed to play Go, which is known as the 
                        most challenging classical game for AI because of its complexity. In fact, Go is over a googol times more 
                        complex than chess having over 10170 possible board combinations. It makes use of multiple deep Neural 
                        Networks and millions of neuron connections. One such Neural Network is the “policy network” which decides 
                        what the next move should be. Another Neural Network, called the “value network”, predicts who will win the 
                        game. The computer was then introduced to multiple amateur players so it can understand the game and how 
                        humans play which helped it become stronger and better at decision-making. Eventually, AlphaGo went on to be 
                        the first AI to defeat Go world champions and ended up becoming the greatest Go player of all time.
                    </p>
                </td>
                <td class="year">
                    <p>
                        <strong>
                            2016 - DeepMind’s AlphaGo AI
                        </strong>
                    </p>
                </td>
              </tr>
        </table>
        <br>
        </div>
        <div class="next-button">
            <button type="button" class="next"><a href="Bibliography.html">Next</a></button>
        </div>
        <div class="previous-button">
            <button type="button" class="previous"><a href="History&Development.html">Previous</a></button>
        </div>
    </body>
</html>